----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
Layer0:				Channels, Height, Width
           Conv2d-1          [-1, 4, 512, 512]             112 (108 weights + 4 biases)
              ReLU-2          [-1, 4, 512, 512]               0
            Conv2d-3          [-1, 4, 512, 512]             148
              ReLU-4          [-1, 4, 512, 512]               0
         AvgPool2d-5          [-1, 4, 256, 256]               0

Layer1:
            Conv2d-6          [-1, 8, 256, 256]             296
              ReLU-7          [-1, 8, 256, 256]               0
            Conv2d-8          [-1, 8, 256, 256]             584
              ReLU-9          [-1, 8, 256, 256]               0
        AvgPool2d-10          [-1, 8, 128, 128]               0
 
Layer2:
           Conv2d-11         [-1, 16, 128, 128]           1,168
             ReLU-12         [-1, 16, 128, 128]               0
           Conv2d-13         [-1, 16, 128, 128]           2,320
             ReLU-14         [-1, 16, 128, 128]               0
        AvgPool2d-15           [-1, 16, 64, 64]               0

Layer3:         
           Conv2d-16           [-1, 32, 64, 64]           4,640  
             ReLU-17           [-1, 32, 64, 64]               0
           Conv2d-18           [-1, 32, 64, 64]           9,248
             ReLU-19           [-1, 32, 64, 64]               0
        AvgPool2d-20           [-1, 32, 32, 32]               0

Layer4:
           Conv2d-21           [-1, 64, 32, 32]          18,496
             ReLU-22           [-1, 64, 32, 32]               0
           Conv2d-23           [-1, 32, 32, 32]          18,464
             ReLU-24           [-1, 32, 32, 32]               0
  ConvTranspose2d-25           [-1, 32, 64, 64]           4,128
           
Layer3:           
           Conv2d-26           [-1, 32, 64, 64]          18,464
             ReLU-27           [-1, 32, 64, 64]               0
           Conv2d-28           [-1, 16, 64, 64]           4,624
             ReLU-29           [-1, 16, 64, 64]               0
  ConvTranspose2d-30         [-1, 16, 128, 128]           1,040
           
Layer2:           
           Conv2d-31         [-1, 16, 128, 128]           4,624
             ReLU-32         [-1, 16, 128, 128]               0
           Conv2d-33          [-1, 8, 128, 128]           1,160
             ReLU-34          [-1, 8, 128, 128]               0
  ConvTranspose2d-35          [-1, 8, 256, 256]             264
           
Layer1:           
           Conv2d-36          [-1, 8, 256, 256]           1,160
             ReLU-37          [-1, 8, 256, 256]               0
           Conv2d-38          [-1, 4, 256, 256]             292
             ReLU-39          [-1, 4, 256, 256]               0
  ConvTranspose2d-40          [-1, 4, 512, 512]              68
           
Layer0:
           Conv2d-41          [-1, 8, 512, 512]             584
             ReLU-42          [-1, 8, 512, 512]               0
           Conv2d-43          [-1, 8, 512, 512]             584
             ReLU-44          [-1, 8, 512, 512]               0
           Conv2d-45          [-1, 3, 512, 512]              27
================================================================
Total params: 92,495
Trainable params: 92,495
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 3.00
Forward/backward pass size (MB): 171.25
Params size (MB): 0.35
Estimated Total Size (MB): 174.60
----------------------------------------------------------------

